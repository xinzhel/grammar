{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval failed in 412 out of 570 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "LLM is generating... for the key:  (\"For the person registered under the name 'Reggie Lewis', can you please find out what their listed nationality is in our 'people' records?\", 'United States', \"I'm sorry, but as an AI assistant, I don't have access to personal records or databases. I suggest reaching out to your company's HR department or relevant personnel to obtain the information you are looking for. They should be able to assist you in finding the listed nationality for the person registered under the name 'Reggie Lewis' in your company's records.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "381it [00:08, 44.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"We are trying to determine the nationality of a person identified as 'Reggie Lewis' in the 'people' database. Can you provide that information?\", 'United States', \"I'm sorry, but I don't have access to specific databases or personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. My primary function is to provide information and answer questions to the best of my knowledge and abilities. If you have any concerns about privacy or data security, please let me know, and I will do my best to address them.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "386it [00:08, 42.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "LLM is generating... for the key:  (\"From the 'people' data set, I need to know the nationality of the individual whose name is recorded as 'Brad Lohaus'. Can you retrieve this information?\", 'United States', \"I apologize, but I don't have access to specific data sets or information about individuals. My capabilities are limited to providing general information and answering questions based on publicly available knowledge.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "393it [00:09, 40.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"The query is specifically designed to determine the nationality of a person whose name matches 'David Butler'. This is data housed within the 'people' database table.\", 'United Kindom', \"As an AI assistant, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. Therefore, I can't provide information about the nationality of a person named 'David Butler' or any other individual. My primary function is to provide information and answer questions to the best of my knowledge and abilities. If you have any concerns about privacy or data security, please let me know, and I will do my best to address them.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "425it [00:09, 45.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"The system is tasked to retrieve and display the nationality of an individual named 'Tim Naegeli'. This information is located in the 'people' table in our database.\", 'United States', \"As an AI assistant, I don't have direct access to your company's database. However, based on the information provided, I cannot find any information about an individual named 'Tim Naegeli' in the given text. It is possible that this information is not included in the provided text or database. To retrieve the nationality of 'Tim Naegeli', you may need to consult your company's internal database or other relevant sources of information.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "436it [00:10, 43.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"We are looking within our 'people' database to find out the nationality of the individual with the name 'Tim Naegeli'.\", 'United States', \"As an AI assistant, I don't have access to personal databases or individual information about people unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. Therefore, I cannot provide you with the nationality of an individual named 'Tim Naegeli' without further information. It is best to consult the appropriate databases or contact the individual directly to obtain this information.\")\n",
      "LLM is generating... for the key:  (\"By searching through our 'people' database, the system is querying the nationality of an individual whose name matches 'Tim Naegeli'.\", 'United States', \"I apologize, but as an AI assistant, I don't have access to personal databases or information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. My primary function is to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can help you with?\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "441it [00:10, 35.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"Look up the name of the graduation college for the individual whose name matches exactly with the placeholder 'Reggie Lewis' in our people dataset.\", 'Northeastern', \"I'm sorry, but as an AI assistant, I don't have access to specific databases or personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to prioritize user privacy and data protection. Therefore, I cannot look up the graduation college for an individual named Reggie Lewis in your people dataset.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [00:10, 39.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"Give me the details of the college from which a person, whose name is specified as 'David Butler', has graduated.\", 'California', \"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. Therefore, I am unable to provide you with the details of the college from which David Butler has graduated. My primary function is to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can help you with?\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "491it [00:11, 51.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "LLM is generating... for the key:  (\"For an individual named 'David Butler', we are searching for the college from which they received their graduation degree.\", 'California', \"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. Therefore, I can't help you with finding the college from which David Butler received his graduation degree.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "497it [01:10,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"What we're trying to do here is search for the specific university where the person named 'David Butler' completed their graduation.\", 'California', \"I'm sorry, but I couldn't find any information about a person named 'David Butler' and their graduation from a specific university in the provided sources. It's possible that this information is not available or not mentioned in the given context. If you have any additional details or sources, I can try to assist you further.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "498it [01:10,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"Our target is to pinpoint the graduate school related to the person who goes by the name 'David Butler'.\", 'California', \"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. Therefore, I don't have the ability to pinpoint the graduate school related to a specific person like 'David Butler' unless that information has been provided to me. My primary function is to provide information and answer questions to the best of my knowledge and abilities. Is there anything else I can help you with?\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "503it [01:10,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is generating... for the key:  (\"We are attempting to identify the graduation college associated with the person whose name is given as 'Tim Naegeli'.\", 'Wisconsin–Stevens Point', \"I'm sorry, but I couldn't find any information about the graduation college associated with a person named 'Tim Naegeli'. It's possible that this information is not publicly available or that there is no notable person with that name in relation to a specific graduation college.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "570it [01:11,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "RAG failed in 448 out of 570 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.append('..')\n",
    "from grammar.eval.match import SemanticsMatch\n",
    "\n",
    "\n",
    "def judge_retrieval_result(result):\n",
    "    result['true_document_ids'] = set([int(r) for r in result['true_document_ids']])\n",
    "    result['retrieved_document_ids'] = set([int(r) for r in result['retrieved_document_ids']])\n",
    "    result['retrieval_judgement'] = 1 if result['true_document_ids'] == result['retrieved_document_ids'] else 0\n",
    "    return result\n",
    "\n",
    "def judge_rag_result(result, semnatics_match, open_domain=False):\n",
    "    if 'judgement' in result:\n",
    "        print(\"Judgement already exists\")\n",
    "        return result\n",
    "    if open_domain and result['retrieval_judgement'] == 0:\n",
    "        result[\"judgement\"] = \"Incorrect\"\n",
    "    else:\n",
    "        result[\"judgement\"] = semnatics_match.generate((result[\"query\"], result[\"answer\"], result[\"gpt_response\"][0]), verbose=True)[0]\n",
    "    return result\n",
    "\n",
    "\n",
    "linguistic_attr = 'long'\n",
    "root_dir = 'spider'\n",
    "open_domain = True\n",
    "semnatics_match = SemanticsMatch.from_file(root_dir=root_dir, verbalize_attrs=linguistic_attr)\n",
    "file_path = f'{root_dir}/eval_results/results_{linguistic_attr}_balanced.json'\n",
    "with open(file_path) as f:\n",
    "    results = json.load(f)\n",
    "num_retrieval_failure = sum([result['retrieval_judgement']==0 for result in results])\n",
    "print(f\"Retrieval failed in {num_retrieval_failure} out of {len(results)} examples\")\n",
    "import time\n",
    "for i, result in tqdm(enumerate(results)):\n",
    "    # sleep for 20 seconds after 9 examples\n",
    "    # if results.index(result) % 9 == 0 and results.index(result) != 0:\n",
    "    #     print(\"Sleeping for 20 seconds\")\n",
    "    #     time.sleep(20)\n",
    "    #     print(\"Waking up\")\n",
    "    result = judge_rag_result(result, semnatics_match, open_domain)\n",
    "num_rag_failure = sum([result['judgement']==\"Incorrect\" for result in results])\n",
    "print(f\"RAG failed in {num_rag_failure} out of {len(results)} examples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "semnatics_match.save(root_dir=f'{root_dir}', override=True)\n",
    "semnatics_match.llm.gpt_usage_record.write_usage(model_name='chatgptk' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure json serializable\n",
    "for result in results:\n",
    "    result['true_document_ids'] = list(result['true_document_ids'])\n",
    "    result['retrieved_document_ids'] = list(result['retrieved_document_ids'])\n",
    "\n",
    "# save results\n",
    "with open(f'{root_dir}/eval_results/results_{linguistic_attr}_balanced.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
