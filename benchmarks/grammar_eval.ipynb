{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval failed in 251 out of 397 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Judgement already exists\n",
      "Sleeping for 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/397 [00:04<02:55,  2.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mindex(result) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m results\u001b[38;5;241m.\u001b[39mindex(result) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleeping for 20 seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaking up\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m result \u001b[38;5;241m=\u001b[39m judge_rag_result(result, semnatics_match)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.append('..')\n",
    "from grammar.eval.match import SemanticsMatch\n",
    "\n",
    "\n",
    "def judge_retrieval_result(result):\n",
    "    result['true_document_ids'] = set([int(r) for r in result['true_document_ids']])\n",
    "    result['retrieved_document_ids'] = set([int(r) for r in result['retrieved_document_ids']])\n",
    "    result['retrieval_judgement'] = 1 if result['true_document_ids'] == result['retrieved_document_ids'] else 0\n",
    "    return result\n",
    "\n",
    "def judge_rag_result(result, semnatics_match):\n",
    "    if 'judgement' in result:\n",
    "        print(\"Judgement already exists\")\n",
    "        return result\n",
    "    # if result['retrieval_judgement'] == 0:\n",
    "    #     result[\"judgement\"] = \"Incorrect\"\n",
    "    # else:\n",
    "    result[\"judgement\"] = semnatics_match.generate((result[\"query\"], result[\"answer\"], result[\"gpt_response\"][0]), verbose=True)[0]\n",
    "    return result\n",
    "\n",
    "\n",
    "linguistic_attr = 'short'\n",
    "root_dir = 'spider'\n",
    "semnatics_match = SemanticsMatch.from_file(root_dir=root_dir, verbalize_attrs=linguistic_attr)\n",
    "file_path = f'{root_dir}/eval_results/results_{linguistic_attr}.json'\n",
    "with open(file_path) as f:\n",
    "    results = json.load(f)\n",
    "num_retrieval_failure = sum([result['retrieval_judgement']==0 for result in results])\n",
    "print(f\"Retrieval failed in {num_retrieval_failure} out of {len(results)} examples\")\n",
    "import time\n",
    "for result in tqdm(results):\n",
    "    # sleep for 20 seconds after 9 examples\n",
    "    if results.index(result) % 9 == 0 and results.index(result) != 0:\n",
    "        print(\"Sleeping for 20 seconds\")\n",
    "        time.sleep(20)\n",
    "        print(\"Waking up\")\n",
    "    result = judge_rag_result(result, semnatics_match)\n",
    "num_rag_failure = sum([result['judgement']==\"Incorrect\" for result in results])\n",
    "print(f\"RAG failed in {num_rag_failure} out of {len(results)} examples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "semnatics_match.save(root_dir=f'{root_dir}', override=True)\n",
    "semnatics_match.llm.gpt_usage_record.write_usage(model_name='chatgpt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure json serializable\n",
    "for result in results:\n",
    "    result['true_document_ids'] = list(result['true_document_ids'])\n",
    "    result['retrieved_document_ids'] = list(result['retrieved_document_ids'])\n",
    "\n",
    "# save results\n",
    "with open(f'{root_dir}/eval_results/results_{linguistic_attr}.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
