{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from grammar.db_tool import DBTool\n",
    "from grammar.llm import AnyOpenAILLM\n",
    "from grammar.sql_template_generator import SQLTemplateGenerator\n",
    "from grammar.text_template_generator import TextTemplateGenerator\n",
    "from grammar.qa_generator import QADataGenerator\n",
    "\n",
    "\n",
    "llm = AnyOpenAILLM(model_name = \"gpt4-short\") \n",
    "\n",
    "setup_env = \"spider\"\n",
    "if setup_env == \"spider\" or setup_env == \"spider_closed\":\n",
    "    database_name = 'spider'\n",
    "    connection_string = f'sqlite:///{database_name}/rel_database/company_employee.sqlite'\n",
    "    schemas = [('company',), ('people',), ('company', 'people')]\n",
    "elif setup_env == \"aurp\":\n",
    "    database_name = 'Aurp'\n",
    "    connection_string = \"mysql+pymysql://root:!wasdB793050@localhost:3306/Aurp\"\n",
    "    schemas = [('client',), ('employee',), ('project', )]\n",
    "db_tool = DBTool(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 2 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 1 generations for the input `k` exist in `cache_generations`! No need to generate more.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate SQL Query Templates\n",
    "file_path = f\"{setup_env}/SQLTemplateGenerator/sql_templates.json\"\n",
    "sql_template_generator = SQLTemplateGenerator.from_file(file_path, sql_connection=connection_string, llm=llm)\n",
    "entities_to_sql_templates = sql_template_generator.generate_batch(schemas, override=False, verbose=True)\n",
    "sql_templates = [tpl for entity, tpls in entities_to_sql_templates.items() for tpl in tpls]\n",
    "# sql_template_generator.save(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 10 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 10 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 10 generations for the input `k` exist in `cache_generations`! No need to generate more.\n",
      "The 10 generations for the input `k` exist in `cache_generations`! No need to generate more.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate Text Query Templates\n",
    "linguistic_attr = \"long\"\n",
    "file_path = f'{setup_env}/TextTemplateGenerator/{linguistic_attr}.json'\n",
    "text_template_generator = TextTemplateGenerator.from_file(file_path=file_path, verbalize_attrs=linguistic_attr, llm=llm) # Load existing generations to avoid re-generation\n",
    "sql_to_text_templates = text_template_generator.generate_batch(sql_templates, verbose=True, num_generations=10, override=False)\n",
    "# text_template_generator.save(file_path=file_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate Evaluation Data (Text Queries and Answers)\n",
    "with_ids = False\n",
    "if with_ids:\n",
    "    # This cell generates sql with IDs for evaluating the effectiveness of our framework since IDs align with the document ID within evaluation retrievals\n",
    "    # SHOULD NOT be used when you apply the framework in the real world\n",
    "    sql_template_with_id_generator = SQLTemplateGenerator.from_file(f\"{setup_env}/SQLTemplateGenerator/sql_templates_with_ids.json\", sql_connection=connection_string, llm=llm)\n",
    "    entities_to_sql_templates_with_ids = sql_template_with_id_generator.generate_batch(schemas, override=False, verbose=True)\n",
    "    sql_templates_with_ids = [tpl for entity, tpls in entities_to_sql_templates_with_ids.items() for tpl in tpls]\n",
    "    sql_to_text_templates_with_ids = {}\n",
    "    for t, t_id in zip(sql_templates, sql_templates_with_ids):\n",
    "        sql_to_text_templates_with_ids[t_id] = sql_to_text_templates[t]\n",
    "    sql_to_text_templates = sql_to_text_templates_with_ids\n",
    "    save_file = f\"{linguistic_attr}_with_ids.json\"\n",
    "else:\n",
    "    save_file = f\"{linguistic_attr}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced = False\n",
    "if unbalanced:\n",
    "    print(\"Number of text templates before unbalancing:\", len([tpl for tpls in sql_to_text_templates.values() for tpl in tpls]))\n",
    "    if linguistic_attr == \"long\":\n",
    "        print(\"only use one text template for each SQL template for client and employee tables amd all text templates for project table\")\n",
    "        sql_to_text_templates_unbalanced = {}\n",
    "        for sql, text_templates in sql_to_text_templates.items():\n",
    "            if \"FROM Client\" in sql or \"FROM Employee\" in sql:\n",
    "                sql_to_text_templates_unbalanced[sql] = [text_templates[0]]\n",
    "            else:\n",
    "                sql_to_text_templates_unbalanced[sql] = text_templates\n",
    "    elif linguistic_attr == \"short\":\n",
    "        print('use the first two text templates for each SQL template')\n",
    "        sql_to_text_templates_unbalanced = {sql: text_templates[:2] for sql, text_templates in sql_to_text_templates.items()}\n",
    "        \n",
    "    sql_to_text_templates = sql_to_text_templates_unbalanced \n",
    "    print(\"Number of text templates after unbalancing:\", len([tpl for tpls in sql_to_text_templates.values() for tpl in tpls]))\n",
    "    save_file = save_file[:-5]+\"_unbalanced.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of generated SQL queries:  57\n",
      "The number of generated text queries:  570\n"
     ]
    }
   ],
   "source": [
    "qa_generator = QADataGenerator(db_tool)\n",
    "all_answers_to_text_queries = qa_generator.generate(sql_to_text_templates)\n",
    "qa_generator.print_query_stats(all_answers_to_text_queries)\n",
    "qa_generator.save(all_answers_to_text_queries, database_name, save_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How About Using Existing Queries?\n",
    "# import json\n",
    "# file_name = \"spider-database/database/company_employee/company_employee.json\"\n",
    "# with open(f\"{file_name}\", 'r') as f:\n",
    "#     filtered_data = json.load(f)\n",
    "# questions = [example['question'] for example in filtered_data]\n",
    "# sql_queries = [example['query'] for example in filtered_data]\n",
    "# questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
